#!/usr/bin/env python
# -*- coding: utf-8 -*-

# stdlib imports
import argparse
import os.path
from configobj import ConfigObj
import urllib.request
import urllib.error
import urllib.parse
import tempfile
import re
import os
import json


# third party imports
from mapio.shake import getHeaderData
from mapio.gdal import GDALGrid
import numpy as np
from impactutils.io.cmd import get_command_output
from mapio.shake import ShakeGrid

# local imports
from gfail.conf import correct_config_filepaths
import gfail.logisticmodel as LM
from gfail.godt import godt2008
from gfail.savelayers import savelayers
from gfail.makemaps import (parseConfigLayers, parseMapConfig,
                            modelMap, interactiveMap)
from gfail.webpage import makeWebpage


def main(args):
    # TODO: ADD CONFIG VALIDATION STEP THAT MAKES SURE ALL THE FILES EXIST
    if args.set_default_paths:
        set_default_paths(args)
        print('default paths set, continuing...\n')

    if args.list_default_paths:
        list_default_paths()
        return

    if args.reset_default_paths:
        reset_default_paths()
        return

    # Figure out what models will be run
    if args.shakefile is not None:  # user intends to actually run some models
        shakefile = args.shakefile
        # make output location for things
        if args.output_filepath is None:
            outdir = os.getcwd()
        else:
            outdir = args.output_filepath

        if (args.hdf5 or args.make_static_pngs or
                args.make_static_pdfs or
                args.make_interactive_plots or
                args.gis):
            if not os.path.exists(outdir):
                os.makedirs(outdir)

        # download if is url
        #cleanup = False
        if not os.path.isfile(shakefile):
            if isURL(shakefile):
                # getGridURL returns a named temporary file object
                shakefile = getGridURL(shakefile)
                # cleanup = True  # Be sure to delete it after
            else:
                raise NameError('Could not find "%s" as a file or a valid url'
                                % (shakefile))
                return
        eventid = getHeaderData(shakefile)[0]['event_id']

        if args.unnest_folder:
            outfolder = os.path.join(outdir, eventid)
            if not os.path.exists(outfolder):
                os.makedirs(outfolder)
        else:
            outfolder = outdir

        config = args.config

        if args.config_filepath is not None:
            # only add config_filepath if full filepath not given and file
            # ext is .ini
            if (not os.path.isabs(config) and
                    os.path.splitext(config)[-1] == '.ini'):
                config = os.path.join(args.config_filepath, config)

        if os.path.splitext(config)[-1] == '.ini':
            temp = ConfigObj(config)
            if len(temp) == 0:
                raise Exception(
                    'Could not find specified .ini file: %s' % config)
            if args.data_path is not None:
                temp = correct_config_filepaths(args.data_path, temp)
            configs = [temp]
            conffail = []
        else:
            # input is a list of config files
            f = open(config, 'r')
            configlist = f.readlines()
            configs = []
            conffail = []
            for conf in configlist:
                conf = conf.replace('\n', '')
                if not os.path.isabs(conf):
                    # only add config_filepath if full filepath not given
                    conf = os.path.join(args.config_filepath, conf)
                try:
                    temp = ConfigObj(conf)
                    if temp:
                        if args.data_path is not None:
                            temp = correct_config_filepaths(args.data_path,
                                                            temp)
                        configs.append(temp)
                    else:
                        conffail.append(conf)
                except:
                    conffail.append(conf)

        print('Running the following models:')

        for conf in configs:
            print('\t%s\n' % conf.keys()[0])
        if len(conffail) > 0:
            print('Could not find or read in the following config files:\n')
            for conf in conffail:
                print('\t%s\n' % conf)
            print('\nContinuing...\n')

        if args.set_bounds is not None:
            if 'zoom' in args.set_bounds:
                temp = args.set_bounds.split(',')
                print('Using %s threshold of %1.1f to cut model bounds'
                      % (temp[1].strip(), float(temp[2].strip())))
                bounds = get_bounds(shakefile, temp[1].strip(),
                                    float(temp[2].strip()))
            else:
                temp = eval(args.set_bounds)
                latmin = temp[0]
                latmax = temp[1]
                lonmin = temp[2]
                lonmax = temp[3]
                bounds = {'xmin': lonmin, 'xmax': lonmax,
                          'ymin': latmin, 'ymax': latmax}
            print('Applying bounds of lonmin %1.2f, lonmax %1.2f, '
                  'latmin %1.2f, latmax %1.2f'
                  % (bounds['xmin'], bounds['xmax'],
                     bounds['ymin'], bounds['ymax']))
        else:
            bounds = None
        filenames = []
        if args.make_webpage:
            results = []

        # pre-read in ocean trimming file polygons so only do this step once
        if args.trimfile is not None:
            if not os.path.exists(args.trimfile):
                print(
                    'trimfile defined does not exist: %s\nOcean will not be trimmed' % args.trimfile)
                trimfile = None
            elif os.path.splitext(args.trimfile)[1] != '.shp':
                print('trimfile must be a shapefile, ocean will not be trimmed')
                trimfile = None
            else:
                trimfile = args.trimfile
        else:
            trimfile = None

        # Get finite fault ready, if exists

        if args.finite_fault is not None:
            if os.path.splitext(args.finite_fault)[-1] == '.txt':
                ffault = text_to_json(args.finite_fault)
            elif os.path.splitext(args.finite_fault)[-1] == '.json':
                ffault = args.finite_fault
            else:
                print('Could not read in finite fault, continuing without it')
                ffault = None
        else:
            ffault = args.finite_fault

        # Loop over config files
        for conf in configs:
            modelname = conf.keys()[0]
            print('Now running %s' % modelname)
            modelfunc = conf[modelname]['funcname']
            if modelfunc == 'LogisticModel':
                lm = LM.LogisticModel(
                    shakefile,
                    conf,
                    uncertfile=args.uncertfile,
                    saveinputs=args.save_inputs,
                    bounds=bounds,
                    numstd=float(args.std),
                    trimfile=trimfile)
                maplayers = lm.calculate()
            elif modelfunc == 'godt2008':
                maplayers = godt2008(
                    shakefile,
                    conf,
                    uncertfile=args.uncertfile,
                    saveinputs=args.save_inputs,
                    bounds=bounds,
                    numstd=float(args.std),
                    trimfile=trimfile)
            else:
                print('Unknown model function specified in config for %s '
                      'model, skipping to next config' % modelfunc)
                continue

            # time1 = datetime.datetime.utcnow().strftime('%d%b%Y_%H%M')
            # filename = ('%s_%s_%s' % (eventid, modelname, time1))

            if args.appendname is not None:
                filename = ('%s_%s_%s' % (eventid, modelname, args.appendname))
            else:
                filename = ('%s_%s' % (eventid, modelname))
            if args.hdf5:
                filenameh = filename + '.hdf5'
                if os.path.exists(filenameh):
                    os.remove(filenameh)
                savelayers(maplayers, os.path.join(outfolder, filenameh))

            if args.make_static_pdfs or args.make_static_pngs:
                plotorder, logscale, lims, colormaps, maskthreshes = \
                    parseConfigLayers(maplayers, conf)
                mapconfig = ConfigObj(args.mapconfig)

                kwargs = parseMapConfig(
                    mapconfig, fileext=args.mapdata_filepath)
                junk, filenames1 = modelMap(
                    maplayers, shakefile,
                    suptitle=conf[modelname]['shortref'],
                    boundaries=None,
                    zthresh=0.,
                    lims=lims,
                    plotorder=plotorder,
                    maskthreshes=maskthreshes,
                    maproads=False,
                    mapcities=True,
                    colormaps=colormaps,
                    savepdf=args.make_static_pdfs,
                    savepng=args.make_static_pngs,
                    printparam=True,
                    inventory_shapefile=None,
                    outputdir=outfolder,
                    outfilename=filename,
                    scaletype='continuous',
                    logscale=logscale, **kwargs)
                for filen in filenames1:
                    filenames.append(filen)

                # make model only plots too
                if len(maplayers) > 1:
                    plotorder, logscale, lims, colormaps, maskthreshes = \
                        parseConfigLayers(maplayers, conf, keys=['model'])
                    junk, filenames1 = modelMap(
                        maplayers, shakefile,
                        suptitle=conf[modelname]['shortref'], boundaries=None,
                        zthresh=0., lims=lims, plotorder=plotorder,
                        maskthreshes=maskthreshes, maproads=False,
                        mapcities=True, savepdf=args.make_static_pdfs,
                        savepng=args.make_static_pngs, printparam=True,
                        inventory_shapefile=None, outputdir=outfolder,
                        outfilename=filename + '-just_model',
                        colormaps=colormaps, scaletype='continuous',
                        logscale=logscale, **kwargs)
                    for filen in filenames1:
                        filenames.append(filen)
            if args.make_interactive_plots:
                plotorder, logscale, lims, colormaps, maskthreshes = \
                    parseConfigLayers(maplayers, conf)
                junk, filenames1 = interactiveMap(
                    maplayers, plotorder=plotorder, shakefile=shakefile,
                    inventory_shapefile=None, maskthreshes=maskthreshes,
                    colormaps=colormaps, isScenario=False,
                    scaletype='continuous', lims=lims, logscale=logscale,
                    ALPHA=0.7, outputdir=outfolder, outfilename=filename,
                    tiletype='Stamen Terrain', separate=True,
                    faultfile=ffault)
                for filen in filenames1:
                    filenames.append(filen)

            if args.make_webpage:
                # Compile into list of results for later
                results.append(maplayers)
                # Make GIS files that are always needed for website if they aren't already being made
                if not args.gis:
                    filen = os.path.join(outfolder, '%s_model.bil'
                                         % filename)
                    fileh = os.path.join(outfolder, '%s_model.hdr'
                                         % filename)
                    fileg = os.path.join(outfolder, '%s_model.tif'
                                         % filename)

                    GDALGrid.copyFromGrid(
                        maplayers['model']['grid']).save(filen)

                    # convert to geotif
                    cmd = 'gdal_translate -a_srs EPSG:4326 -of GTiff %s %s' % (
                        filen, fileg)
                    rc, so, se = get_command_output(cmd)
                    # os.remove(filen)
                    # os.remove(fileh)
                    filenames.append(fileg)

                # Make binary output for ShakeCast
                filef = os.path.join(outfolder, '%s_model.flt'
                                     % filename)
                # And get name of header
                filefh = os.path.join(outfolder, '%s_model.hdr'
                                      % filename)
                # Make file
                write_floats(filef, maplayers['model']['grid'])
                filenames.append(filef)
                filenames.append(filefh)

            if args.gis:

                for key in maplayers:
                    # Get simplified name of key for file naming
                    RIDOF = '[+-]?(?=\d*[.eE])(?=\.?\d)'\
                            '\d*\.?\d*(?:[eE][+-]?\d+)?'
                    OPERATORPAT = '[\+\-\*\/]*'
                    keyS = re.sub(OPERATORPAT, '', key)
                    # remove floating point numbers
                    keyS = re.sub(RIDOF, '', keyS)
                    # remove parentheses
                    keyS = re.sub('[()]*', '', keyS)
                    # remove any blank spaces
                    keyS = keyS.replace(' ', '')
                    filen = os.path.join(outfolder, '%s_%s.bil'
                                         % (filename, keyS))
                    fileh = os.path.join(outfolder, '%s_%s.hdr'
                                         % (filename, keyS))
                    fileg = os.path.join(outfolder, '%s_%s.tif'
                                         % (filename, keyS))

                    GDALGrid.copyFromGrid(maplayers[key]['grid']).save(filen)
                    cmd = 'gdal_translate -a_srs EPSG:4326 -of GTiff %s %s' % (
                        filen, fileg)
                    rc, so, se = get_command_output(cmd)
                    # os.remove(filen)
                    # os.remove(fileh)
                    filenames.append(fileg)

        if args.make_webpage:
            outputs = makeWebpage(results, configs, args.web_template,
                                  shakefile, outfolder=outfolder,
                                  includeAlert=args.alert, cleanup=True,
                                  faultfile=ffault)
            filenames = filenames + outputs

        # Write shakefile to a file for use later
        shake_file = open(os.path.join(outfolder, "shakefile.txt"), "w")
        shake_file.write(shakefile)
        shake_file.close()

        print('\nFiles created:\n')
        for filen in filenames:
            print('%s' % filen)

        # if cleanup:
        #    os.remove(shakefile)


def getGridURL(gridurl):
    """
    Args:
        gridurl (str): url for Shakemap grid.xml file.

    Returns:
        file object corresponding to the url.
    """

    f = None
    fh = None
    with urllib.request.urlopen(gridurl) as fh:
        data = fh.read().decode('utf-8')
        with tempfile.NamedTemporaryFile(delete=False, mode='w') as f:
            f.write(data)

    return f.name


def isURL(gridurl):
    """
    This function determines if the provided string is a valid url

    Args:
        gridurl (str): url to check.

    Returns:
        bool: True if griurl is a valid url, False otherwise.
    """

    isURL = False
    try:
        urllib.request.urlopen(gridurl)
        isURL = True
    except:
        pass
    return isURL


def set_default_paths(args):
    """
    Creates a file called .gfail_defaults that contains default path
    information to simplify running gfail. Can be overwritten by any manually
    entered paths. This updates any existing .gfail_defaults file. If
    args.data_path is 'reset' then any existing defaults will be removed.
    """
    filename = os.path.join(os.path.expanduser('~'), '.gfail_defaults')
    if os.path.exists(filename):
        D = ConfigObj(filename)
    else:
        D = {}
    if args.data_path is not None:
        if args.data_path == 'reset':
            D.pop('data_path')
        else:
            # check that it's a valid path
            if os.path.exists(args.data_path):
                D.update({'data_path': args.data_path})
            else:
                print('Path given for data_path does not exist: %s'
                      % args.data_path)
    if args.output_filepath is not None:
        if args.output_filepath == 'reset':
            D.pop('output_filepath')
        else:
            # check that it's a valid path
            if os.path.exists(args.output_filepath):
                D.update({'output_filepath': args.output_filepath})
            else:
                print('Path given for output_filepath does not exist: %s'
                      % args.output_filepath)
    if args.config_filepath is not None:
        if args.config_filepath == 'reset':
            D.pop('config_filepath')
        else:
            # check that it's a valid path
            if os.path.exists(args.config_filepath):
                D.update({'config_filepath': args.config_filepath})
            else:
                print('Path given for config_filepath does not exist: %s'
                      % args.config_filepath)
    if args.mapconfig is not None:
        if args.mapconfig == 'reset':
            D.pop('mapconfig')
        else:
            # check that it's a valid path
            if os.path.exists(args.mapconfig):
                D.update({'mapconfig': args.mapconfig})
            else:
                print('Path given for mapconfig does not exist: %s'
                      % args.mapconfig)
    if args.mapdata_filepath is not None:
        if args.mapdata_filepath == 'reset':
            D.pop('mapdata_filepath')
        else:
            # check that it's a valid path
            if os.path.exists(args.mapdata_filepath):
                D.update({'mapdata_filepath': args.mapdata_filepath})
            else:
                print('Path given for mapdata_filepath does not exist: %s'
                      % args.mapdata_filepath)
    if args.web_template is not None:
        if args.web_template == 'reset':
            D.pop('web_template')
        else:
            # check that it's a valid path
            if os.path.exists(args.web_template):
                D.update({'web_template': args.web_template})
            else:
                print('Path given for webpage templates does not exist: %s'
                      % args.web_template)
    if args.trimfile is not None:
        if args.trimfile == 'reset':
            D.pop('trim')
        else:
            # check that it's a valid path and that it's a shapefile
            if os.path.exists(args.trimfile):
                filename4, fileextension = os.path.splitext(args.trimfile)
                if fileextension == '.shp':
                    D.update({'trimfile': args.trimfile})
                else:
                    print('Ocean trimming file is not a shapefile: %s'
                          % args.trimfile)
            else:
                print('Path given for ocean trimming file does not exist: %s'
                      % args.trimfile)
    print('New default paths set.\n')

    if D:
        C = ConfigObj(D)
        C.filename = filename
        C.write()
        list_default_paths()
    else:
        print('no defaults set because no paths were input\n')


def list_default_paths():
    """
    Lists all default paths currently set.
    """
    filename = os.path.join(os.path.expanduser('~'), '.gfail_defaults')
    if os.path.exists(filename):
        D = ConfigObj(filename)
        print('Default paths currently set to:\n')
        for key in D:
            print('\t%s = %s' % (key, D[key]))
    else:
        print('No default paths currently set\n')


def reset_default_paths():
    """
    Clear default path file
    """
    filename = os.path.join(os.path.expanduser('~'), '.gfail_defaults')
    if os.path.exists(filename):
        os.remove(filename)
        print('Default paths cleared\n')
    else:
        print('No default paths currently set\n')


def get_bounds(shakefile, parameter='pga', threshold=2):
    """
    Get the boundaries of the shakemap that include all areas with shaking
    above the defined threshold.

    Args:
        shakefile (str): Path to shakemap file.
        parameter (str): Either 'pga' or 'pgv'.
        threshold (float): Minimum value of parameter of interest, in units
            of %g for pga and cm/s for pgv. The default value of 2 %g is based
            on minimum pga threshold ever observed to have triggered landslides
            from Jibson and Harp (2016).

    Returns:
        dict: A dictionary with keys 'xmin', 'xmax', 'ymin', and 'ymax' and
        some dummy keys that are unused.
    """
    shakemap = ShakeGrid.load(shakefile, adjust='res')
    if parameter == 'pga':
        vals = shakemap.getLayer('pga')
    elif parameter == 'pgv':
        vals = shakemap.getLayer('pgv')
    else:
        raise Exception('parameter not valid')
    xmin, xmax, ymin, ymax = vals.getBounds()
    lons = np.linspace(xmin, xmax, vals.getGeoDict().nx)
    lats = np.linspace(ymax, ymin, vals.getGeoDict().ny)
    row, col = np.where(vals.getData() > float(threshold))
    lonmin = lons[col].min()
    lonmax = lons[col].max()
    latmin = lats[row].min()
    latmax = lats[row].max()

    # dummy fillers, only really care about bounds
    boundaries1 = {'dx': 100, 'dy': 100., 'nx': 100., 'ny': 100}

    if xmin < lonmin:
        boundaries1['xmin'] = lonmin
    else:
        boundaries1['xmin'] = xmin
    if xmax > lonmax:
        boundaries1['xmax'] = lonmax
    else:
        boundaries1['xmax'] = xmax
    if ymin < latmin:
        boundaries1['ymin'] = latmin
    else:
        boundaries1['ymin'] = ymin
    if ymax > latmax:
        boundaries1['ymax'] = latmax
    else:
        boundaries1['ymax'] = ymax

    return boundaries1


def text_to_json(textffile):
    """
    Simplification of text_to_json from shakelib.rupture.factory
    """
    with open(textffile, 'r') as f:
        lines = f.readlines()
    x = []
    y = []
    z = []
    reference = ''
    # convert to geojson
    for line in lines:
        sline = line.strip()
        if sline.startswith('#'):
            reference += sline.strip('#').strip('Source: ')
            continue
        if sline.startswith('>'):
            if len(x):  # start of new line segment
                x.append(np.nan)
                y.append(np.nan)
                z.append(np.nan)
                continue
            else:  # start of file
                continue
        if not len(sline.strip()):
            continue
        parts = sline.split()

        y.append(float(parts[0]))
        x.append(float(parts[1]))
        if len(parts) >= 3:
            z.append(float(parts[2]))
        else:
            print('Fault file has no depths, assuming zero depth')
            z.append(0.0)
        coords = []
        poly = []
        for lon, lat, dep in zip(x, y, z):
            if np.isnan(lon):
                coords.append(poly)
                poly = []
            else:
                poly.append([lon, lat, dep])
        if poly != []:
            coords.append(poly)

    d = {
        "type": "FeatureCollection",
        "metadata": {
            'reference': reference
        },
        "features": [
            {
                "type": "Feature",
                "properties": {
                    "rupture type": "rupture extent"
                },
                "geometry": {
                    "type": "MultiPolygon",
                    "coordinates": [coords]
                }
            }
        ]
    }
    return json.dumps(d)


def write_floats(filename, grid2d):
    """Create a binary (with acc. header file) version of a Grid2D object.

    Given a filename input of "probability.flt", this function will
    create that file, plus a text file called "probability.hdr".

    Args:
        filename (str): String filename to write (i.e., 'probability.flt')
        grid2d (Grid2D): MapIO Grid2D object.
    """
    geodict = grid2d.getGeoDict().asDict()
    array = grid2d.getData().astype('float32')
    np.save(filename, array)
    npyfilename = filename + '.npy'
    os.rename(npyfilename, filename)
    fpath, fname = os.path.split(filename)
    fbase, _ = os.path.splitext(fname)
    hdrfile = os.path.join(fpath, fbase + '.hdr')
    f = open(hdrfile, 'wt')
    for key, value in geodict.items():
        if isinstance(value, int):
            fmt = '%s = %i\n'
        elif isinstance(value, float):
            fmt = '%s = %.4f\n'
        else:
            fmt = '%s = %s\n'
        f.write(fmt % (key, value))
    f.close()


if __name__ == '__main__':

    # See if there is a default path file, load in if there is and
    # replace any nones
    defaults = os.path.join(os.path.expanduser('~'), '.gfail_defaults')
    data_path = None
    output_filepath = None
    config_filepath = None
    mapconfig = None
    mapdata_filepath = None
    web_template = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'pelican', 'theme')
    trimfile = None

    if os.path.exists(defaults):
        D = ConfigObj(defaults)
        for key in D:
            if key == 'data_path':
                data_path = D[key]
            elif key == 'output_filepath':
                output_filepath = D[key]
            elif key == 'config_filepath':
                config_filepath = D[key]
            elif key == 'mapconfig':
                mapconfig = D[key]
            elif key == 'mapdata_filepath':
                mapdata_filepath = D[key]
            elif key == 'web_template':
                web_template = D[key]
            elif key == 'trimfile':
                trimfile = D[key]

    parser = argparse.ArgumentParser(
        description='Run ground failure models on input ShakeMap grid.')
    parser.add_argument(
        'config', metavar='config', nargs='?',
        help='single config file of model to run (.ini extension), or text '
             'file listing config files (do not use .ini extension)')
    parser.add_argument(
        'shakefile', nargs='?',
        help='single ShakeMap grid.xml file or url')
    parser.add_argument(
        '-a', '--appendname', metavar='appendname', nargs='?',
        help='append word to file names to describe current run',
        default=None)
    parser.add_argument(
        '-c', '--config-filepath', metavar='configfilepath', nargs='?',
        default=config_filepath,
        help='Filepath where config files are located, default is '
             'defaultconfigfiles folder of groundfailure repository')
    parser.add_argument(
        '-d', '--data-path', metavar='datafilepath', nargs='?',
        default=data_path,
        help='Set file path to model input data (only needed if file paths '
        'in config are relative)')
    parser.add_argument(
        '-m', '--mapconfig', metavar='mapconfig', nargs='?',
        help='full file path to config file containing mapping options',
        default=mapconfig)
    parser.add_argument(
        '-md', '--mapdata-filepath', metavar='mapdatapath', nargs='?',
        help='Set file path to mapping input data (only needed if file '
             'paths in mapconfig are relative)',
        default=mapdata_filepath)
    parser.add_argument(
        '-o', '--output-filepath', metavar='outfilepath', nargs='?',
        default=output_filepath,
        help='Filepath for output files, uses current directory if '
             'not specified')
    parser.add_argument(
        '-t', '--web-template', metavar='template', nargs='?',
        default=web_template,
        help='location of directory containing pelican files and templates')
    parser.add_argument(
        '-u', '--uncertfile', metavar='uncertfile', nargs='?',
        help='single ShakeMap uncertainty.xml file', default=None)
    parser.add_argument(
        '-tr', '--trimfile', metavar='trimocean', nargs='?', default=trimfile,
        help='Location of shapefile of land masses to use to trim areas over water')

    parser.add_argument(
        '-b', '--set-bounds', type=str,
        metavar=('latmin, latmax, lonmin, lonmax'), nargs='?',
        help="Set bounds of model run using four floats in this format, "
             "including quotes: 'latmin, latmax, lonmin, lonmax', default "
             "uses shakemap bounds, 'zoom, parameter, threshold' in single "
             "quotes uses a shakemap threshold value, e.g. 'zoom, pga, 2' "
             "where 2 is in percent g",
        default=None)
    parser.add_argument(
        '-f', '--finite-fault', metavar='finitefault', nargs='?',
        default=None, help='geojson file to show on interactive maps')
    parser.add_argument(
        '-s', '--std', metavar='numstd', nargs='?',
        help='Number of ground motion standard deviations to use '
             '(only used if uncertainty file used)',
        default=1.)

    # Binary

    parser.add_argument(
        '--gis', action='store_true', default=False,
        help='Save GIS file (ESRI .bil format) of model result')
    parser.add_argument(
        '--hdf5', action='store_true', default=False,
        help='Save model results as MultiHazard HDF file (MapIO)')
    parser.add_argument(
        '-i', '--save-inputs', action='store_true', default=False,
        help='Save input layer grids with model output')
    parser.add_argument(
        '-pd', '--make-static-pdfs', action='store_true', default=False,
        help='Make static plots for each model')
    parser.add_argument(
        '-pi', '--make-interactive-plots', action='store_true', default=False,
        help='Make interactive html plots for each model')
    parser.add_argument(
        '-pn', '--make-static-pngs', action='store_true', default=False,
        help='Make static plots for each model')

    parser.add_argument(
        '-l', '--list-default-paths', action='store_true', default=False,
        help='See listing of currently set default paths')
    parser.add_argument(
        '-set', '--set-default-paths', action='store_true', default=False,
        help='Sets paths given as inputs as defaults '
             '(overwrites existing values)')
    parser.add_argument(
        '-reset', '--reset-default-paths', action='store_true', default=False,
        help='Clears all existing default paths')
    parser.add_argument(
        '-w', '--make-webpage', action='store_true', default=False,
        help='Create webpage that summarizes all model results, '
             'including interactive maps')
    parser.add_argument(
        '-n', '--unnest-folder', action='store_true', default=True,
        help='do not nest in output folder with eventid as name '
             '(default is it will nest)')
    parser.add_argument(
        '--alert', action='store_true', default=False,
        help='Determine and report alert levels. Default is false')
    # parser.add_argument('-e', '--exercise', action='store_true', default=False,
    #                    help='Exercise tests (for developers)')

    pargs = parser.parse_args()
    main(pargs)
